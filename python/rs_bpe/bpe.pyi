# ruff: noqa: A002
from __future__ import annotations

class ParallelOptions:
    def __init__(
        self,
        min_batch_size: int | None = ...,
        chunk_size: int | None = ...,
        max_threads: int | None = ...,
    ) -> None: ...
    @property
    def min_batch_size(self) -> int: ...
    @property
    def chunk_size(self) -> int: ...
    @property
    def max_threads(self) -> int: ...

class Tokenizer:
    def count(self, input: str) -> int: ...
    def count_till_limit(self, input: str, limit: int) -> int | None: ...
    def encode(
        self, input: str, allowed_special: set[str] | None = ...
    ) -> list[int]: ...
    def encode_batch(
        self, texts: list[str], allowed_special: set[str] | None = ...
    ) -> tuple[list[list[int]], int, float]: ...
    def encode_batch_parallel(
        self,
        texts: list[str],
        options: ParallelOptions | None = ...,
        allowed_special: set[str] | None = ...,
    ) -> tuple[list[list[int]], int, float, int]: ...
    def decode(self, tokens: list[int]) -> str | None: ...
    def decode_batch(self, batch_tokens: list[list[int]]) -> list[str | None]: ...
    def decode_batch_parallel(
        self, batch_tokens: list[list[int]], options: ParallelOptions | None = ...
    ) -> list[str | None]: ...
    @property
    def special_tokens(self) -> dict[str, int] | None: ...

def cl100k_base() -> Tokenizer: ...
def o200k_base() -> Tokenizer: ...
def deepseek_base() -> Tokenizer: ...
def is_cached_cl100k() -> bool: ...
def is_cached_deepseek() -> bool: ...
def is_cached_o200k() -> bool: ...
def get_num_threads() -> int: ...
